{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f7220860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import words, cmudict\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "700a1916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL\n",
       "0      37  https://insights.blackcoffer.com/ai-in-healthc...\n",
       "1      38  https://insights.blackcoffer.com/what-if-the-c...\n",
       "2      39  https://insights.blackcoffer.com/what-jobs-wil...\n",
       "3      40  https://insights.blackcoffer.com/will-machine-...\n",
       "4      41  https://insights.blackcoffer.com/will-ai-repla..."
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('C:/Users/Dev/OneDrive/Desktop/Jupyter/Input.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d4141118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://insights.blackcoffer.com/will-machine-replace-the-human-in-the-future-of-work/\n"
     ]
    }
   ],
   "source": [
    "#Check if indexing works\n",
    "print(df.iloc[3]['URL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bbec9d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114\n"
     ]
    }
   ],
   "source": [
    "output_df = pd.DataFrame()\n",
    "output_df['URL_ID'] = df['URL_ID']\n",
    "output_df['URL'] = df['URL']\n",
    "length = len(df)\n",
    "print(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "35c2423b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://insights.blackcoffer.com/ai-in-healthcare-to-improve-patient-outcomes/\n",
      "110\n",
      "37\n",
      "https://insights.blackcoffer.com/what-if-the-creation-is-taking-over-the-creator/\n",
      "97\n",
      "43\n",
      "https://insights.blackcoffer.com/what-jobs-will-robots-take-from-humans-in-the-future/\n",
      "102\n",
      "43\n",
      "https://insights.blackcoffer.com/will-machine-replace-the-human-in-the-future-of-work/\n",
      "110\n",
      "31\n",
      "https://insights.blackcoffer.com/will-ai-replace-us-or-work-with-us/\n",
      "93\n",
      "30\n",
      "https://insights.blackcoffer.com/man-and-machines-together-machines-are-more-diligent-than-humans-blackcoffe/\n",
      "88\n",
      "26\n",
      "https://insights.blackcoffer.com/in-future-or-in-upcoming-years-humans-and-machines-are-going-to-work-together-in-every-field-of-work/\n",
      "63\n",
      "15\n",
      "https://insights.blackcoffer.com/how-neural-networks-can-be-applied-in-various-areas-in-the-future/\n",
      "0\n",
      "0\n",
      "https://insights.blackcoffer.com/how-machine-learning-will-affect-your-business/\n",
      "74\n",
      "16\n",
      "https://insights.blackcoffer.com/deep-learning-impact-on-areas-of-e-learning/\n",
      "110\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,10):\n",
    "    url = df.iloc[i]['URL']\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content,'html.parser')\n",
    "    text_content = soup.get_text()\n",
    "    name = i+37\n",
    "    print(url)\n",
    "    with open(f'{name}.txt', 'w') as file:\n",
    "        file.write(text_content)\n",
    "        \n",
    "        with open(f'{name}.txt', 'r') as file:\n",
    "            content = file.read()\n",
    "\n",
    "        # Read the words to delete from the word file\n",
    "        with open('StopWords_Names.txt', 'r') as word_file:\n",
    "            words_to_delete = [word.strip() for word in word_file.read().split()]\n",
    "\n",
    "        with open('StopWords_Geographic.txt', 'r') as word_file:\n",
    "            words_to_delete = [word.strip() for word in word_file.read().split()]\n",
    "\n",
    "        with open('StopWords_Generic.txt', 'r') as word_file:\n",
    "            words_to_delete = [word.strip() for word in word_file.read().split()]\n",
    "\n",
    "        with open('StopWords_GenericLong.txt', 'r') as word_file:\n",
    "            words_to_delete = [word.strip() for word in word_file.read().split()]\n",
    "\n",
    "        with open('StopWords_Currencies.txt', 'r') as word_file:\n",
    "            words_to_delete = [word.strip() for word in word_file.read().split()]\n",
    "\n",
    "        with open('StopWords_Auditor.txt', 'r') as word_file:\n",
    "            words_to_delete = [word.strip() for word in word_file.read().split()]\n",
    "\n",
    "        with open('StopWords_DatesandNumbers.txt', 'r') as word_file:\n",
    "            words_to_delete = [word.strip() for word in word_file.read().split()]\n",
    "\n",
    "        # Delete the words from the content\n",
    "        for word in words_to_delete:\n",
    "            content = content.replace(word, '')\n",
    "\n",
    "        # Open the text file in write mode\n",
    "        with open(f'{name}.txt', 'w') as file:\n",
    "            file.write(content)\n",
    "        \n",
    "        with open(f'{name}.txt', 'r') as file:\n",
    "            content = file.read()\n",
    "\n",
    "        tokens = word_tokenize(content)\n",
    "        from nltk.tokenize import word_tokenize\n",
    "\n",
    "        # Read positive words from a file\n",
    "        positive_words = set()\n",
    "        with open('positive-words.txt', 'r') as file:\n",
    "            for line in file:\n",
    "                positive_words.add(line.strip())\n",
    "\n",
    "        # Sample tokenized data\n",
    "        tokens = word_tokenize(content)\n",
    "\n",
    "        # Segregate positive words\n",
    "        positive_tokens = [token for token in tokens if token.lower() in positive_words]\n",
    "\n",
    "        # Print positive words\n",
    "        positive_score = len(positive_tokens)\n",
    "        print(positive_score)\n",
    "\n",
    "        negative_words = set()\n",
    "        with open('negative-words.txt', 'r') as file:\n",
    "            for line in file:\n",
    "                negative_words.add(line.strip())\n",
    "\n",
    "        negative_tokens = [token for token in tokens if token.lower() in negative_words]\n",
    "        negative_score = len(negative_tokens)\n",
    "        print(negative_score)\n",
    "        \n",
    "        if(positive_score and negative_score)==0:\n",
    "            continue\n",
    "\n",
    "        polarity_score = (positive_score-negative_score)/(positive_score+negative_score) + 0.000001\n",
    "        #print(polarity_score)\n",
    "        subj_score = (positive_score+negative_score)/(len(tokens))\n",
    "        #print(subj_score)\n",
    "\n",
    "        sentences = sent_tokenize(content)\n",
    "        a = len(set(tokens))\n",
    "        b = len(set(sentences))\n",
    "        avg_sentence_length = a/b\n",
    "        #print(avg_sentence_length)\n",
    "\n",
    "        pronouncing_dict = cmudict.dict()\n",
    "\n",
    "        # Function to count syllables in a word\n",
    "        def count_syllables(word):\n",
    "            # Check if the word is in the pronouncing dictionary\n",
    "            if word.lower() in pronouncing_dict:\n",
    "                # Get the pronunciation of the word\n",
    "                pronunciation = pronouncing_dict[word.lower()][0]\n",
    "                # Count the number of syllables by counting stress marks\n",
    "                return len([ph for ph in pronunciation if ph[-1].isdigit()])\n",
    "            else:\n",
    "                # Return 0 if the word is not in the dictionary (unknown word)\n",
    "                return 0\n",
    "\n",
    "        # Identify words with two or more syllables\n",
    "        complex_words = [token for token in tokens if count_syllables(token) >= 2]\n",
    "        num_complex = len(complex_words)\n",
    "        percent_complex = len(complex_words)/len(tokens)\n",
    "        #print(percent_complex)\n",
    "\n",
    "        fog_index = 0.4*(avg_sentence_length + percent_complex)\n",
    "        #print(fog_index)\n",
    "\n",
    "        avg_word_sentence = len(tokens)/len(sentences)\n",
    "        #print(avg_word_sentence)\n",
    "\n",
    "        word_count = len(tokens)\n",
    "        #print(word_count)\n",
    "\n",
    "        # cleaned_tokens = [token for token in tokens if token not in string.punctuation]\n",
    "        # num_clean_tokens = len(cleaned_tokens)\n",
    "        def count_syllable_2(word):\n",
    "            # Remove trailing \"es\" and consider it as a single syllable\n",
    "            if word.endswith((\"es\",\"ed\",\"ad\")):\n",
    "                word = word[:-2]\n",
    "\n",
    "            # Count vowels in the word\n",
    "            num_vowels = sum(1 for char in word.lower() if char in 'aeiou')\n",
    "\n",
    "            return num_vowels\n",
    "        syllable_counts = [count_syllable_2(word) for word in tokens]\n",
    "        syl_count_word = len(syllable_counts)\n",
    "        avg_word_length = len(text_content)/len(tokens)\n",
    "        \n",
    "        pattern = r'\\b(I|we|my|ours|us)\\b'\n",
    "\n",
    "        # Find and count personal pronouns\n",
    "        matches = re.findall(pattern,text_content, flags=re.IGNORECASE)\n",
    "        count_personal = len(matches)\n",
    "        #print(count_personal)\n",
    "\n",
    "        output_df.at[i, 'POSITIVE SCORE'] = positive_score\n",
    "        output_df.at[i,'POSITIVE SCORE'] = positive_score\n",
    "        output_df.at[i,'NEGATIVE SCORE'] = negative_score\n",
    "        output_df.at[i,'POLARITY SCORE'] = polarity_score\n",
    "        output_df.at[i,'SUBJECTIVITY SCORE'] = subj_score\n",
    "        output_df.at[i,'AVERAGE SENTENCE LENGTH'] = avg_sentence_length\n",
    "        output_df.at[i,'PERCENTAGE OF COMPLEX WORDS'] = percent_complex\n",
    "        output_df.at[i,'FOG INDEX'] = fog_index\n",
    "        output_df.at[i,'AVERAGE WORDS PER SENTENCE'] = avg_word_sentence\n",
    "        output_df.at[i,'COMPLEX WORD COUNT'] = num_complex\n",
    "        output_df.at[i,'WORD COUNT'] = word_count\n",
    "        output_df.at[i,'SYLLABLE PER WORD'] = syl_count_word\n",
    "        output_df.at[i,'PERSONAL PRONOUNS'] = count_personal\n",
    "        output_df.at[i,'AVG WORD LENGTH'] = avg_word_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f97cef6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVERAGE SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVERAGE WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>110.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.496600</td>\n",
       "      <td>0.048403</td>\n",
       "      <td>13.372093</td>\n",
       "      <td>0.395456</td>\n",
       "      <td>5.507020</td>\n",
       "      <td>35.313953</td>\n",
       "      <td>1201.0</td>\n",
       "      <td>3037.0</td>\n",
       "      <td>3037.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.455384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>97.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.385715</td>\n",
       "      <td>0.052711</td>\n",
       "      <td>9.715789</td>\n",
       "      <td>0.312877</td>\n",
       "      <td>4.011466</td>\n",
       "      <td>27.957895</td>\n",
       "      <td>831.0</td>\n",
       "      <td>2656.0</td>\n",
       "      <td>2656.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5.931852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>102.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.406898</td>\n",
       "      <td>0.049320</td>\n",
       "      <td>11.072165</td>\n",
       "      <td>0.386735</td>\n",
       "      <td>4.583560</td>\n",
       "      <td>30.309278</td>\n",
       "      <td>1137.0</td>\n",
       "      <td>2940.0</td>\n",
       "      <td>2940.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>6.278571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>110.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.560285</td>\n",
       "      <td>0.049526</td>\n",
       "      <td>9.311321</td>\n",
       "      <td>0.340358</td>\n",
       "      <td>3.860672</td>\n",
       "      <td>26.607477</td>\n",
       "      <td>969.0</td>\n",
       "      <td>2847.0</td>\n",
       "      <td>2847.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>6.043203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>93.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.512196</td>\n",
       "      <td>0.041123</td>\n",
       "      <td>12.119565</td>\n",
       "      <td>0.345035</td>\n",
       "      <td>4.985840</td>\n",
       "      <td>32.510870</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>2991.0</td>\n",
       "      <td>2991.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>6.088599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL  POSITIVE SCORE  \\\n",
       "0      37  https://insights.blackcoffer.com/ai-in-healthc...           110.0   \n",
       "1      38  https://insights.blackcoffer.com/what-if-the-c...            97.0   \n",
       "2      39  https://insights.blackcoffer.com/what-jobs-wil...           102.0   \n",
       "3      40  https://insights.blackcoffer.com/will-machine-...           110.0   \n",
       "4      41  https://insights.blackcoffer.com/will-ai-repla...            93.0   \n",
       "\n",
       "   NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  \\\n",
       "0            37.0        0.496600            0.048403   \n",
       "1            43.0        0.385715            0.052711   \n",
       "2            43.0        0.406898            0.049320   \n",
       "3            31.0        0.560285            0.049526   \n",
       "4            30.0        0.512196            0.041123   \n",
       "\n",
       "   AVERAGE SENTENCE LENGTH  PERCENTAGE OF COMPLEX WORDS  FOG INDEX  \\\n",
       "0                13.372093                     0.395456   5.507020   \n",
       "1                 9.715789                     0.312877   4.011466   \n",
       "2                11.072165                     0.386735   4.583560   \n",
       "3                 9.311321                     0.340358   3.860672   \n",
       "4                12.119565                     0.345035   4.985840   \n",
       "\n",
       "   AVERAGE WORDS PER SENTENCE  COMPLEX WORD COUNT  WORD COUNT  \\\n",
       "0                   35.313953              1201.0      3037.0   \n",
       "1                   27.957895               831.0      2656.0   \n",
       "2                   30.309278              1137.0      2940.0   \n",
       "3                   26.607477               969.0      2847.0   \n",
       "4                   32.510870              1032.0      2991.0   \n",
       "\n",
       "   SYLLABLE PER WORD  PERSONAL PRONOUNS  AVG WORD LENGTH  \n",
       "0             3037.0               27.0         6.455384  \n",
       "1             2656.0               30.0         5.931852  \n",
       "2             2940.0               26.0         6.278571  \n",
       "3             2847.0               44.0         6.043203  \n",
       "4             2991.0               45.0         6.088599  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d0588fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.to_excel('output.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98e5829",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
